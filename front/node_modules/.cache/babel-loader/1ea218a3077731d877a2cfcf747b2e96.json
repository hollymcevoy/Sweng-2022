{"ast":null,"code":"\"use strict\"; // Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.SynthesisContext = void 0;\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\n\nvar SynthesisContext =\n/** @class */\nfunction () {\n  function SynthesisContext(speechSynthesizer) {\n    this.privContext = {};\n    this.privSpeechSynthesizer = speechSynthesizer;\n  }\n  /**\n   * Adds a section to the synthesis.context object.\n   * @param sectionName Name of the section to add.\n   * @param value JSON serializable object that represents the value.\n   */\n\n\n  SynthesisContext.prototype.setSection = function (sectionName, value) {\n    this.privContext[sectionName] = value;\n  };\n\n  Object.defineProperty(SynthesisContext.prototype, \"audioOutputFormat\", {\n    /**\n     * Sets the audio output format for synthesis context generation.\n     * @param format {AudioOutputFormatImpl} the output format\n     */\n    set: function (format) {\n      this.privAudioOutputFormat = format;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  SynthesisContext.prototype.toJSON = function () {\n    var synthesisSection = this.buildSynthesisContext();\n    this.setSection(\"synthesis\", synthesisSection);\n    return JSON.stringify(this.privContext);\n  };\n\n  SynthesisContext.prototype.buildSynthesisContext = function () {\n    return {\n      audio: {\n        metadataOptions: {\n          bookmarkEnabled: !!this.privSpeechSynthesizer.bookmarkReached,\n          sentenceBoundaryEnabled: false,\n          visemeEnabled: !!this.privSpeechSynthesizer.visemeReceived,\n          wordBoundaryEnabled: !!this.privSpeechSynthesizer.wordBoundary\n        },\n        outputFormat: this.privAudioOutputFormat.requestAudioFormatString\n      },\n      language: {\n        autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n      }\n    };\n  };\n\n  return SynthesisContext;\n}();\n\nexports.SynthesisContext = SynthesisContext;","map":{"version":3,"mappings":"cAAA;AACA;;;;;;AAKA;;;;;AAIA;AAAA;AAAA;AAKI,4BAAYA,iBAAZ,EAAgD;AAJxC,uBAA0C,EAA1C;AAKJ,SAAKC,qBAAL,GAA6BD,iBAA7B;AACH;AAED;;;;;;;AAKOE,0CAAP,UAAkBC,WAAlB,EAAuCC,KAAvC,EAAiD;AAC7C,SAAKC,WAAL,CAAiBF,WAAjB,IAAgCC,KAAhC;AACH,GAFM;;AAQPE,wBAAWJ,0BAAX,EAAW,mBAAX,EAA4B;AAJ5B;;;;SAIA,UAA6BK,MAA7B,EAA0D;AACtD,WAAKC,qBAAL,GAA6BD,MAA7B;AACH,KAF2B;qBAAA;;AAAA,GAA5B;;AAIOL,sCAAP;AAEI,QAAMO,gBAAgB,GAAsB,KAAKC,qBAAL,EAA5C;AACA,SAAKC,UAAL,CAAgB,WAAhB,EAA6BF,gBAA7B;AAEA,WAAOG,IAAI,CAACC,SAAL,CAAe,KAAKR,WAApB,CAAP;AACH,GANM;;AAQCH,qDAAR;AACI,WAAO;AACHY,WAAK,EAAE;AACHC,uBAAe,EAAE;AACbC,yBAAe,EAAG,CAAC,CAAC,KAAKf,qBAAL,CAA2BgB,eADlC;AAEbC,iCAAuB,EAAE,KAFZ;AAGbC,uBAAa,EAAG,CAAC,CAAC,KAAKlB,qBAAL,CAA2BmB,cAHhC;AAIbC,6BAAmB,EAAG,CAAC,CAAC,KAAKpB,qBAAL,CAA2BqB;AAJtC,SADd;AAOHC,oBAAY,EAAE,KAAKf,qBAAL,CAA2BgB;AAPtC,OADJ;AAUHC,cAAQ,EAAE;AACNC,qBAAa,EAAE,KAAKzB,qBAAL,CAA2B0B;AADpC;AAVP,KAAP;AAcH,GAfO;;AAgBZ;AAlDA;;AAAaC","names":["speechSynthesizer","privSpeechSynthesizer","SynthesisContext","sectionName","value","privContext","Object","format","privAudioOutputFormat","synthesisSection","buildSynthesisContext","setSection","JSON","stringify","audio","metadataOptions","bookmarkEnabled","bookmarkReached","sentenceBoundaryEnabled","visemeEnabled","visemeReceived","wordBoundaryEnabled","wordBoundary","outputFormat","requestAudioFormatString","language","autoDetection","autoDetectSourceLanguage","exports"],"sources":["/Users/dylanmurray/Sweng-2022/front/node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/src/common.speech/SynthesisContext.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\nimport { AudioOutputFormatImpl } from \"../sdk/Audio/AudioOutputFormat\";\r\nimport { SpeechSynthesizer } from \"../sdk/Exports\";\r\n\r\n/**\r\n * Represents the JSON used in the synthesis.context message sent to the speech service.\r\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\r\n */\r\nexport class SynthesisContext {\r\n    private privContext: { [section: string]: any } = {};\r\n    private privSpeechSynthesizer: SpeechSynthesizer;\r\n    private privAudioOutputFormat: AudioOutputFormatImpl;\r\n\r\n    constructor(speechSynthesizer: SpeechSynthesizer) {\r\n        this.privSpeechSynthesizer = speechSynthesizer;\r\n    }\r\n\r\n    /**\r\n     * Adds a section to the synthesis.context object.\r\n     * @param sectionName Name of the section to add.\r\n     * @param value JSON serializable object that represents the value.\r\n     */\r\n    public setSection(sectionName: string, value: any): void {\r\n        this.privContext[sectionName] = value;\r\n    }\r\n\r\n    /**\r\n     * Sets the audio output format for synthesis context generation.\r\n     * @param format {AudioOutputFormatImpl} the output format\r\n     */\r\n    public set audioOutputFormat(format: AudioOutputFormatImpl) {\r\n        this.privAudioOutputFormat = format;\r\n    }\r\n\r\n    public toJSON(): string {\r\n\r\n        const synthesisSection: ISynthesisSection = this.buildSynthesisContext();\r\n        this.setSection(\"synthesis\", synthesisSection);\r\n\r\n        return JSON.stringify(this.privContext);\r\n    }\r\n\r\n    private buildSynthesisContext(): ISynthesisSection {\r\n        return {\r\n            audio: {\r\n                metadataOptions: {\r\n                    bookmarkEnabled: (!!this.privSpeechSynthesizer.bookmarkReached),\r\n                    sentenceBoundaryEnabled: false,\r\n                    visemeEnabled: (!!this.privSpeechSynthesizer.visemeReceived),\r\n                    wordBoundaryEnabled: (!!this.privSpeechSynthesizer.wordBoundary),\r\n                },\r\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\r\n            },\r\n            language: {\r\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\r\n            }\r\n        };\r\n    }\r\n}\r\n\r\ninterface ISynthesisSection {\r\n    audio: {\r\n        outputFormat: string,\r\n        metadataOptions: {\r\n            bookmarkEnabled: boolean,\r\n            wordBoundaryEnabled: boolean,\r\n            visemeEnabled: boolean,\r\n            sentenceBoundaryEnabled: boolean,\r\n        }\r\n    };\r\n    language: {\r\n        autoDetection: boolean\r\n    };\r\n}\r\n"]},"metadata":{},"sourceType":"script"}